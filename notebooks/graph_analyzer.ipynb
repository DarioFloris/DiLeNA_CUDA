{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cudf\n",
    "import cugraph\n",
    "from cugraph import Graph, connected_components\n",
    "from numba import cuda, jit, int32\n",
    "import numpy as np \n",
    "import cupy as cp\n",
    "from math import ceil, floor, log2\n",
    "import seaborn as sns\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
    "from cugraph.generators import multi_rmat, rmat\n",
    "\n",
    "GPU_MEM_LIMIT = (18*1024**3) / 1e9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Analysis:\n",
    "\n",
    "    graph_properties = [\n",
    "        'nodes_number',\n",
    "        'edges_number',\n",
    "        'avg_clustering_coefficient',\n",
    "        'degree_distribution_tot',\n",
    "        'degree_distribution_in',\n",
    "        'degree_distribution_out'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, direction=False):\n",
    "        self.graph = Graph(directed=direction)\n",
    "        self.__properties = {} # Store all the extra variables\n",
    "\n",
    "    def new_property(self, **kwargs):\n",
    "        for kwarg in kwargs:\n",
    "            if kwarg not in self.graph_properties:\n",
    "                raise KeyError(f'Got an unexpected key \"{kwarg}\"')\n",
    "        \n",
    "        self.__properties.update(kwargs)\n",
    "\n",
    "    def get_graph(self):\n",
    "        return self.graph\n",
    "\n",
    "\n",
    "    def get_property(self, key):\n",
    "        try:\n",
    "            return self.__properties[key]\n",
    "        except KeyError:\n",
    "            sys.exit(f'Invalid key {key}')\n",
    "\n",
    "    def get_properties(self):\n",
    "        return self.__properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA Kernels to compute:\n",
    "# - Degree Distribution\n",
    "# - Adjacency Lists ( directed and undirected )\n",
    "# - Edges between neighbors (directed and undirected )\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def compute_degree_distribution(n, count, percentage):\n",
    "    \"\"\"\n",
    "    - n                 number of vertices\n",
    "    - count             input cudf series\n",
    "    - percentage        output cudf series\n",
    "    \"\"\"\n",
    "    i = cuda.threadIdx.x + (cuda.blockIdx.x * cuda.blockDim.x)\n",
    "    \n",
    "    if i < count.size:\n",
    "        percentage[i] = (count[i] / n) * 100\n",
    "\n",
    "@cuda.jit\n",
    "def adj_list(nodes, src, dst, undirected, out):\n",
    "    tx = cuda.threadIdx.x\n",
    "    bx = cuda.blockIdx.x\n",
    "    dx = cuda.blockDim.x\n",
    "    tid = dx * bx + tx\n",
    "    pos = 0\n",
    "    if tid < len(nodes):\n",
    "        u_node = nodes[tid]\n",
    "        for j in range(len(src)):\n",
    "            if u_node == src[j]:\n",
    "                out[tid, pos] = dst[j]\n",
    "                pos += 1\n",
    "            if undirected:\n",
    "                if u_node == dst[j]:\n",
    "                    out[tid, pos] = src[j]\n",
    "                    pos += 1\n",
    "\n",
    "@cuda.jit\n",
    "def reciprocal_count(A, nodes, src, dst, M, N, out):\n",
    "    ty = cuda.threadIdx.y; tx = cuda.threadIdx.x\n",
    "    by = cuda.blockIdx.y; bx = cuda.blockIdx.x\n",
    "    dy = cuda.blockDim.y; dx = cuda.blockDim.x\n",
    "    row = dy * by + ty\n",
    "    column = dx * bx + tx\n",
    "    \n",
    "    if row < M and column < N and A[row, column] != -1:\n",
    "        v_node = A[row, column]\n",
    "        u_node = nodes[row]\n",
    "        for j in range(len(src)):\n",
    "            if v_node == src[j] and u_node == dst[j]:\n",
    "                cuda.atomic.add(out, row, 1)\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def find_uv_edges(A, src, dst, M, N, out):\n",
    "    ty = cuda.threadIdx.y; tx = cuda.threadIdx.x\n",
    "    by = cuda.blockIdx.y; bx = cuda.blockIdx.x\n",
    "    dy = cuda.blockDim.y; dx = cuda.blockDim.x\n",
    "    row = dy * by + ty\n",
    "    column = dx * bx + tx\n",
    "    \n",
    "    if row < M and column < N and A[row, column] != -1:\n",
    "        u_node = A[row, column]\n",
    "        for j in range(N):\n",
    "            v_node = A[row, j]\n",
    "            if v_node != -1 and u_node != v_node:\n",
    "                common = explore_edges(u_node, v_node, src, dst)\n",
    "                cuda.atomic.add(out, row, common)\n",
    "                \n",
    "#            j += 1\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def explore_edges(u, v, src, dst):\n",
    "    result, k = 0, 0\n",
    "    while k < src.size:\n",
    "        if u == src[k] and v == dst[k]:\n",
    "            result += 1\n",
    "        k += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def lcc(nodes, edges, df_degree, undirected, lcc_array):\n",
    "    tid = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    if tid < len(nodes):\n",
    "        lcc = 0.0\n",
    "        item = edges[tid]\n",
    "        if item > 0:\n",
    "            node_deg = df_degree[tid]\n",
    "            if undirected:\n",
    "                lcc = 2 * (item / (node_deg * (node_deg - 1)))\n",
    "            else:\n",
    "                lcc = item / (node_deg * (node_deg - 1))\n",
    "\n",
    "        cuda.atomic.add(lcc_array, 0, lcc)\n",
    "\n",
    "@cuda.jit\n",
    "def gnp_erdos_renyi(p, rng_states, M, N, matrix):\n",
    "    tid = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    if tid < M:\n",
    "        for pos in range(N):\n",
    "            rnd = xoroshiro128p_uniform_float32(rng_states, tid)\n",
    "            if rnd <= p:\n",
    "                matrix[tid, pos] = 1\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def align(src, const):\n",
    "    tid = cuda.blockDim.x * cuda.blockIdx.x + cuda.threadIdx.x\n",
    "    if tid < len(src):\n",
    "        src[tid] = src[tid] + const\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GPU_MEM_LIMIT = (18*1024**3) / 1e9\n",
    "\n",
    "def load_data(filepath):\n",
    "    df_edges = cudf.read_csv(filepath, delimiter=',', names=['src','dst','wt'],\n",
    "                             dtype=['int32','int32','float64'])\n",
    "                                \n",
    "    df_edges.drop_duplicates(subset=['src', 'dst'], inplace=True)\n",
    "    df_edges.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    return df_edges\n",
    "\n",
    "def build_graph(\n",
    "    graph, \n",
    "    edges, \n",
    "    source='src',\n",
    "    destination='dst',\n",
    "    edge_attr='wt',\n",
    "    renumber=True,\n",
    "    store_transposed=False\n",
    ") -> Graph:\n",
    "\n",
    "    graph.from_cudf_edgelist(edges, source, destination, edge_attr, renumber, \n",
    "                             store_transposed)\n",
    "\n",
    "    print(f'Building graph completed')\n",
    "    return graph\n",
    "\n",
    "def view_edgelist(graph):\n",
    "    edges = graph.view_edge_list()\n",
    "    return edges\n",
    "\n",
    "    \n",
    "def nodes(graph):\n",
    "    res = graph.nodes().sort_values(ascending=True).to_cupy()\n",
    "    return res\n",
    "\n",
    "def number_of_vertices(graph):\n",
    "    res = graph.number_of_vertices()\n",
    "    print(f'Number of nodes calculated')\n",
    "    return res\n",
    "\n",
    "def number_of_edges(graph):\n",
    "    res = graph.number_of_edges()\n",
    "    print(f'Number of edges calculated')\n",
    "    return res\n",
    "\n",
    "def degree(graph, mode='tot'):\n",
    "\n",
    "    if mode in 'tot': df = graph.degree()\n",
    "    elif mode in 'in': df = graph.in_degree()\n",
    "    elif mode in 'out': df = graph.out_degree()\n",
    "\n",
    "    df = df.sort_values(by='vertex', ignore_index=True)\n",
    "    print(f'\"{mode}\" degree calculated')\n",
    "    return df\n",
    "\n",
    "\n",
    "def degree_distribution(n, df, mode='tot') -> cudf.DataFrame:\n",
    "    \"\"\"\n",
    "    - df           cudf dataframe containing in/out/total degree per each node\n",
    "    - n            number of vertices    \n",
    "    - mode         tot OR in OR out degree to specify nothing(??????????????)      \n",
    "    \"\"\"\n",
    "    \n",
    "    degree_series = df['degree'].value_counts()\n",
    "    df_distribution = cudf.DataFrame({'degree': degree_series.index.to_cupy(),\n",
    "                                      'count': degree_series.to_cupy(),\n",
    "                                      'percentage': 0.0})\n",
    "\n",
    "    size = len(df_distribution)\n",
    "    compute_degree_distribution.forall(size)(n, df_distribution['count'],\n",
    "                                                  df_distribution['percentage'])\n",
    "    \n",
    "    print(f'\"{mode}\" degree distribution calculated')\n",
    "    return df_distribution\n",
    "\n",
    "\n",
    "def build_main_weakly_connected_component_edges(graph, edges) -> cudf.DataFrame:\n",
    "    df_components = connected_components(graph, connection='weak')\n",
    "    target_label = df_components['labels'].mode()[0]\n",
    "    df_nodes = df_components[df_components['labels'] == target_label]\n",
    "    edges_list = edges.loc[edges['src'].isin(df_nodes['vertex'])]\n",
    "    \n",
    "    print(f'Main component\\'s edges calculated')\n",
    "    return edges_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_bounds(x, y, bytes_) -> int:\n",
    "    size = ((x * y * bytes_) / 1e9)\n",
    "    if size > GPU_MEM_LIMIT:\n",
    "        x  = compute_bounds(int(x/2), y, bytes_)\n",
    "    return x\n",
    "\n",
    "\n",
    "def init_cc(n, batch_size, iteration, mod):\n",
    "\n",
    "    \"\"\"\n",
    "    - n                 number of vertices of the graph\n",
    "    - batch_size        range of nodes examined each epoch\n",
    "    - iteration         current epoch\n",
    "    - mod               the margin of n / batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    if (batch_size * iteration) <= n:\n",
    "        start = 0 + (batch_size*(iteration - 1))\n",
    "        stop = start + batch_size\n",
    "        M = batch_size\n",
    "    else:\n",
    "        start = 0 + (batch_size*(iteration - 1))\n",
    "        stop = start + mod\n",
    "        M = mod\n",
    "    print(start, stop)\n",
    "    return start, stop, M\n",
    "        \n",
    "    \n",
    "def avg_clustering_coefficient(\n",
    "    n,\n",
    "    src,\n",
    "    dst,\n",
    "    df_degree,\n",
    "    N,\n",
    "    nodes_cp=None,\n",
    "    undirected=False\n",
    "\n",
    ") -> float:\n",
    "\n",
    "\n",
    "    local_ccs = cp.zeros((1,), dtype='float32')\n",
    "    M = compute_bounds(n, N, cp.dtype(cp.int32).itemsize)\n",
    "    epochs = ceil(n / M)\n",
    "    leftovers = n % M\n",
    "     \n",
    "    for i in range(1, epochs+1):  \n",
    "        start, stop, M = init_cc(n, M, i, leftovers)\n",
    "        nodes = cp.arange(start, stop, 1)\n",
    "        if nodes_cp is not None: nodes = nodes_cp[start : stop]\n",
    "        matrix = cp.empty((M, N), dtype='int32')\n",
    "        matrix.fill(-1)\n",
    "        edgespernode = cp.zeros(M, dtype='int32')\n",
    "        reciprocal = cp.zeros(M, dtype='int32')\n",
    "        start_ev = cuda.event()\n",
    "        stop_ev = cuda.event()\n",
    "\n",
    "        threadsperblock = 1024\n",
    "        blockspergrid = (M + (threadsperblock -1)) // threadsperblock\n",
    "        threadsperblock_2D = (32, 32)\n",
    "        blockspergrid_x = (N + (threadsperblock_2D[1] - 1)) // threadsperblock_2D[1]\n",
    "        blockspergrid_y = (M + (threadsperblock_2D[0] - 1)) // threadsperblock_2D[0]\n",
    "        blockspergrid_2D = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "\n",
    "\n",
    "        start_ev.record()\n",
    "        adj_list[blockspergrid, threadsperblock](nodes, src, dst, undirected, matrix)\n",
    "#        reciprocal_count[blockspergrid_2D, threadsperblock_2D](matrix, nodes, src, dst, M, N, reciprocal)\n",
    "        find_uv_edges[blockspergrid_2D, threadsperblock_2D](matrix, src, dst, M, N, edgespernode)       \n",
    "        lcc[blockspergrid, threadsperblock](nodes, edgespernode, df_degree, undirected, local_ccs)\n",
    "        stop_ev.record()\n",
    "        cuda.synchronize()\n",
    "\n",
    "    elapsed_t = (cuda.event_elapsed_time(start_ev, stop_ev) / 1000) / 60\n",
    "    result = local_ccs[0].get() / n\n",
    "    print(f'Average clustering coefficient calculcated. {result}')\n",
    "    print('Elapsed time: %.6f minutes' % elapsed_t)\n",
    "    return result\n",
    "\n",
    "\n",
    "def random_graph_generator(n, edges) -> cudf.DataFrame:\n",
    "    print(f'Generating random graph with ER model...')\n",
    "    L = Graph(directed=True)\n",
    "    df = cudf.DataFrame({'src': None, 'dst': None})\n",
    "    p = edges / (n * (n - 1))\n",
    "    N = n\n",
    "    M = compute_bounds(n, N, cp.dtype(cp.int32).itemsize)\n",
    "    epochs = ceil(n / M)\n",
    "    leftovers = n % M\n",
    "    epoch = 1\n",
    "\n",
    "    while epoch <= epochs:\n",
    "        L.clear()\n",
    "        start, stop, M = init_cc(n, M, epoch, leftovers)\n",
    "        matrix = cp.zeros((M, N), dtype='int32')\n",
    "        threadsperblock = 1024\n",
    "        blockspergrid = (matrix.shape[0] + (threadsperblock - 1)) // threadsperblock\n",
    "        rng_states = create_xoroshiro128p_states(threadsperblock * blockspergrid, seed=42)\n",
    "        gnp_erdos_renyi[blockspergrid, threadsperblock](p, rng_states, M, N, matrix)\n",
    "        a_matrix = np.empty((M,N), dtype='int32')\n",
    "        cp.asnumpy(matrix, stream=None, out=a_matrix)\n",
    "#        arrays.append(a_matrix)\n",
    "        L.from_numpy_array(a_matrix)\n",
    "        df_l = L.view_edge_list()\n",
    "        df_l.pop('weights')\n",
    "        size = len(df['src'])\n",
    "        align.forall(size)(df_l['src'], start)\n",
    "        df = cudf.concat([df, df_l], ignore_index=True)\n",
    "        del a_matrix\n",
    "        del matrix\n",
    "        epoch += 1\n",
    "    \n",
    "#    A = np.concatenate(arrays)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    print(f'Random graph\\'s edges list calculated')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../graphs/ethereum/2020-01-01_2020-01-01/network.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgelist = load_data(input_file)\n",
    "analysis_ = Analysis(direction=True)\n",
    "G = analysis_.get_graph()\n",
    "build_graph(G, df_edgelist, renumber=False)\n",
    "\n",
    "vertex_number_ = number_of_vertices(G)\n",
    "edges_number_ = number_of_edges(G)\n",
    "df_total_deg = degree(G, 'tot')\n",
    "df_in_deg = degree(G, 'in')\n",
    "df_out_deg = degree(G, 'out')\n",
    "df_total_dist = degree_distribution(vertex_number_, df_total_deg, 'tot')\n",
    "df_in_dist = degree_distribution(vertex_number_, df_in_deg, 'in')\n",
    "df_out_dist = degree_distribution(vertex_number_, df_out_deg, 'out')\n",
    "#totals = sns.displot(df_total_dist.to_pandas(), x='degree', kde=True)\n",
    "#outs = sns.displot(df_out_dist.to_pandas(), x='degree', kde=True)\n",
    "#ins = sns.displot(df_in_dist.to_pandas(), x='degree', kde=True)\n",
    "N = df_out_deg['degree'].max()\n",
    "avg_cc = avg_clustering_coefficient(\n",
    "    vertex_number_, \n",
    "    df_edgelist['src'],\n",
    "    df_edgelist['dst'], \n",
    "    df_out_deg['degree'],\n",
    "    N, \n",
    "    undirected=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgelist_mc = build_main_weakly_connected_component_edges(G, df_edgelist)\n",
    "analysis_mc = Analysis(direction=True)\n",
    "G = analysis_mc.get_graph()\n",
    "build_graph(G, df_edgelist_mc, renumber=True)\n",
    "\n",
    "vertex_number_mc = number_of_vertices(G)\n",
    "edges_number_mc = number_of_edges(G)\n",
    "df_total_deg_mc = degree(G, 'tot')\n",
    "df_in_deg_mc = degree(G, 'in')\n",
    "df_out_deg_mc = degree(G, 'out')\n",
    "df_total_dist_mc = degree_distribution(vertex_number_mc, df_total_deg_mc, 'tot')\n",
    "df_in_dist_mc = degree_distribution(vertex_number_mc, df_in_deg_mc, 'in')\n",
    "df_out_dist_mc = degree_distribution(vertex_number_mc, df_out_deg_mc, 'out')\n",
    "#totals = sns.displot(df_total_dist_mc.to_pandas(), x='degree', kde=True)\n",
    "#outs = sns.displot(df_out_dist_mc.to_pandas(), x='degree', kde=True)\n",
    "#ins = sns.displot(df_in_dist_mc.to_pandas(), x='degree', kde=True)\n",
    "vertices_mc = nodes(G)\n",
    "N = df_out_deg_mc['degree'].max()\n",
    "avg_cc_mc = avg_clustering_coefficient(\n",
    "    vertex_number_mc, \n",
    "    df_edgelist_mc['src'],\n",
    "    df_edgelist_mc['dst'], \n",
    "    df_out_deg_mc['degree'],\n",
    "    N,\n",
    "    nodes_cp=vertices_mc,\n",
    "    undirected=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgelist_rnd = random_graph_generator(vertex_number_, edges_number_)\n",
    "analysis_rnd = Analysis(direction=True)\n",
    "G = analysis_rnd.get_graph()\n",
    "build_graph(G, df_edgelist_rnd, edge_attr=None, renumber=False)\n",
    "vertex_number_rnd = number_of_vertices(G)\n",
    "edges_number_rnd = number_of_edges(G)\n",
    "df_total_deg_rnd = degree(G, 'tot')\n",
    "df_in_deg_rnd = degree(G, 'in')\n",
    "df_out_deg_rnd = degree(G, 'out')\n",
    "df_total_dist_rnd = degree_distribution(vertex_number_rnd, df_total_deg_rnd, 'tot')\n",
    "df_in_dist_rnd = degree_distribution(vertex_number_rnd, df_in_deg_rnd, 'in')\n",
    "df_out_dist_rnd = degree_distribution(vertex_number_rnd, df_out_deg_rnd, 'out')\n",
    "#totals = sns.displot(df_total_dist_rnd.to_pandas(), x='degree', kde=True)\n",
    "#outs = sns.displot(df_out_dist_rnd.to_pandas(), x='degree', kde=True)\n",
    "#ins = sns.displot(df_in_dist_rnd.to_pandas(), x='degree', kde=True)\n",
    "N = df_out_deg_rnd['degree'].max()\n",
    "avg_cc_rnd = avg_clustering_coefficient(\n",
    "    vertex_number_rnd,\n",
    "    df_edgelist_rnd['src'],\n",
    "    df_edgelist_rnd['dst'],\n",
    "    df_out_deg_rnd['degree'],\n",
    "    N,\n",
    "    undirected=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgelist_rnd_mc = build_main_weakly_connected_component_edges(G, df_edgelist_rnd)\n",
    "analysis_rnd_mc = Analysis(direction=True)\n",
    "G = analysis_rnd_mc.get_graph()\n",
    "build_graph(G, df_edgelist_rnd_mc, edge_attr=None, renumber=True)\n",
    "vertex_number_rnd_mc = number_of_vertices(G)\n",
    "edges_number_rnd_mc = number_of_edges(G)\n",
    "df_total_deg_rnd_mc = degree(G, 'tot')\n",
    "df_in_deg_rnd_mc = degree(G, 'in')\n",
    "df_out_deg_rnd_mc = degree(G, 'out')\n",
    "df_total_dist_rnd_mc = degree_distribution(vertex_number_rnd_mc, df_total_deg_rnd_mc, 'tot')\n",
    "df_in_dist_rnd_mc = degree_distribution(vertex_number_rnd_mc, df_in_deg_rnd_mc, 'in')\n",
    "df_out_dist_rnd_mc = degree_distribution(vertex_number_rnd_mc, df_out_deg_rnd_mc, 'out')\n",
    "#totals = sns.displot(df_total_dist_rnd_mc.to_pandas(), x='degree', kde=True)\n",
    "#outs = sns.displot(df_out_dist_rnd_mc.to_pandas(), x='degree', kde=True)\n",
    "#ins = sns.displot(df_in_dist_rnd_mc.to_pandas(), x='degree', kde=True)\n",
    "vertices_rnd_mc = nodes(G)\n",
    "N = df_out_deg_rnd_mc['degree'].max()\n",
    "avg_cc_rnd_mc = avg_clustering_coefficient(\n",
    "    vertex_number_rnd_mc,\n",
    "    df_edgelist_rnd_mc['src'],\n",
    "    df_edgelist_rnd_mc['dst'],\n",
    "    df_out_deg_rnd_mc['degree'],\n",
    "    N,\n",
    "    nodes_cp=vertices_rnd_mc,\n",
    "    undirected=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../graphs/litecoin/network.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    COMPUTE AVG_CC ON UNDIRECTED GRAPH\n",
    "\n",
    "In order to properly compute the average clustering coefficient on undirected\n",
    "graphs, we need to:\n",
    "\n",
    "-   Create a directed graph with the given edgelist (downloaded) and\n",
    "    and edge_attr=None to ignore weights numbers\n",
    "-   Transform created graph as an undirected graph\n",
    "-   Take again the new edgelist from the undirected graph\n",
    "\n",
    "\"\"\"\n",
    "df_edgelist_undirected = load_data(input_file)\n",
    "analysis_undirected = Analysis(direction=True)\n",
    "G = analysis_undirected.get_graph()\n",
    "build_graph(G, df_edgelist_undirected, edge_attr=None, renumber=False)\n",
    "G = G.to_undirected()\n",
    "df_edgelist_undirected = view_edgelist(G)\n",
    "vertex_number_undirected = number_of_vertices(G)\n",
    "edges_number_undirected = number_of_edges(G)\n",
    "df_total_deg_undirected = degree(G, 'tot')\n",
    "df_in_deg_undirected = degree(G, 'in')\n",
    "df_out_deg_undirected = degree(G, 'out')\n",
    "df_total_dist_undirected = degree_distribution(vertex_number_undirected, df_total_deg_undirected, 'tot')\n",
    "df_in_dist_undirected = degree_distribution(vertex_number_undirected, df_in_deg_undirected, 'in')\n",
    "df_out_dist_undirected = degree_distribution(vertex_number_undirected, df_out_deg_undirected, 'out')\n",
    "#totals = sns.displot(df_total_dist_undirected.to_pandas(), x='degree', kde=True)\n",
    "#outs = sns.displot(df_out_dist_undirected.to_pandas(), x='degree', kde=True)\n",
    "#ins = sns.displot(df_in_dist_undirected.to_pandas(), x='degree', kde=True)\n",
    "N = df_out_deg_undirected['degree'].max()\n",
    "avg_cc_undirected = avg_clustering_coefficient(\n",
    "    vertex_number_undirected,\n",
    "    df_edgelist_undirected['src'],\n",
    "    df_edgelist_undirected['dst'],\n",
    "    df_out_deg_undirected['degree'],\n",
    "    N,\n",
    "    undirected=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DiLeNa_rapidsai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "205f03a9084886247c431e04be0474db8fe3c88af0920dc2b52a09012fb59654"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
