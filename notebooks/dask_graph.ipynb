{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "import dask.delayed\n",
    "import cugraph\n",
    "from cugraph import Graph\n",
    "import cugraph.dask as dask_cugraph\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cugraph.dask.comms.comms as Comms\n",
    "from numba import cuda, jit, prange\n",
    "from math import ceil\n",
    "import dask.array as da\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
    "import numpy as np\n",
    "\n",
    "GPU_MEM_LIMIT = (18*1024**3) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def compute_degree_distribution(n, count, percentage):\n",
    "    \"\"\"\n",
    "    - n                 number of vertices\n",
    "    - count             input cudf series\n",
    "    - percentage        output cudf series\n",
    "    \"\"\"\n",
    "    i = cuda.threadIdx.x + (cuda.blockIdx.x * cuda.blockDim.x)\n",
    "    \n",
    "    if i < count.size:\n",
    "        percentage[i] = (count[i] / n) * 100\n",
    "\n",
    "@cuda.jit\n",
    "def adj_list(nodes, src, dst, undirected, out):\n",
    "    tx = cuda.threadIdx.x\n",
    "    bx = cuda.blockIdx.x\n",
    "    dx = cuda.blockDim.x\n",
    "    tid = dx * bx + tx\n",
    "    pos = 0\n",
    "    if tid < len(nodes):\n",
    "        u_node = nodes[tid]\n",
    "        for j in range(len(src)):\n",
    "            if u_node == src[j]:\n",
    "                out[tid, pos] = dst[j]\n",
    "                pos += 1\n",
    "            if undirected:\n",
    "                if u_node == dst[j]:\n",
    "                    out[tid, pos] = src[j]\n",
    "                    pos += 1\n",
    "\n",
    "@cuda.jit\n",
    "def reciprocal_count(A, nodes, src, dst, M, N, out):\n",
    "    ty = cuda.threadIdx.y; tx = cuda.threadIdx.x\n",
    "    by = cuda.blockIdx.y; bx = cuda.blockIdx.x\n",
    "    dy = cuda.blockDim.y; dx = cuda.blockDim.x\n",
    "    row = dy * by + ty\n",
    "    column = dx * bx + tx\n",
    "    \n",
    "    if row < M and column < N and A[row, column] != -1:\n",
    "        v_node = A[row, column]\n",
    "        u_node = nodes[row]\n",
    "        for j in range(len(src)):\n",
    "            if v_node == src[j] and u_node == dst[j]:\n",
    "                cuda.atomic.add(out, row, 1)\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def find_uv_edges(A, src, dst, M, N, undirected, out):\n",
    "    ty = cuda.threadIdx.y; tx = cuda.threadIdx.x\n",
    "    by = cuda.blockIdx.y; bx = cuda.blockIdx.x\n",
    "    dy = cuda.blockDim.y; dx = cuda.blockDim.x\n",
    "    row = dy * by + ty\n",
    "    column = dx * bx + tx\n",
    "    \n",
    "    if row < M and column < N and A[row, column] != -1:\n",
    "        u_node = A[row, column]\n",
    "        for j in range(N):\n",
    "            v_node = A[row, j]\n",
    "            if v_node != -1 and u_node != v_node:\n",
    "                common = explore_edges(u_node, v_node, src, dst)\n",
    "                cuda.atomic.add(out, row, common)\n",
    "                if undirected:\n",
    "                    common = explore_edges(v_node, u_node, src, dst)\n",
    "                    cuda.atomic.add(out, row, common)\n",
    "#            j += 1\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def explore_edges(u, v, src, dst):\n",
    "    result, k = 0, 0\n",
    "    while k < src.size:\n",
    "        if u == src[k] and v == dst[k]:\n",
    "            result += 1\n",
    "        k += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def lcc(nodes, edges, df_degree, recip, undirected, lcc_array):\n",
    "    tid = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    if tid < len(nodes):\n",
    "        lcc = 0.0\n",
    "        item = edges[tid]\n",
    "        if item > 0:\n",
    "            node_deg = df_degree[tid]\n",
    "            if undirected:\n",
    "                lcc = item / (node_deg * (node_deg - 1))\n",
    "            else:\n",
    "                lcc = item / (node_deg * (node_deg - 1) - (2 * recip[tid]))\n",
    "\n",
    "        cuda.atomic.add(lcc_array, 0, lcc)\n",
    "\n",
    "@cuda.jit\n",
    "def gnp_erdos_renyi(epoch, p, rng_states, M, N, matrix):\n",
    "    tid = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    if tid < M:\n",
    "        for j in range(N):\n",
    "            rnd = xoroshiro128p_uniform_float32(rng_states, tid*epoch)\n",
    "            if rnd <= p:\n",
    "                matrix[tid, j] = 1\n",
    "\n",
    "@cuda.jit\n",
    "def align(src, const):\n",
    "    tid = cuda.blockDim.x * cuda.blockIdx.x + cuda.threadIdx.x\n",
    "    if tid < len(src):\n",
    "        src[tid] = src[tid] + const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file):\n",
    "    chunksize = dask_cugraph.get_chunksize(input_file)\n",
    "    ddf = dask_cudf.read_csv(\n",
    "        input_file, \n",
    "        chunksize=chunksize, \n",
    "        delimiter=',', \n",
    "        names=['src', 'dst', 'wt'], \n",
    "        dtype=['int32', 'int32', 'float64']\n",
    "    ).drop_duplicates(subset=['src', 'dst'], keep='first').dropna(how='any')\n",
    "\n",
    "    return ddf\n",
    "\n",
    "#TODO build_graph\n",
    "\n",
    "def nodes(graph):\n",
    "    vertices = graph.nodes().compute().sort_values(ascending=True).to_cupy()\n",
    "    return vertices\n",
    "    \n",
    "def number_of_vertices(graph):\n",
    "    res = graph.nodes()\n",
    "    return len(res)\n",
    "\n",
    "def number_of_edges(graph):\n",
    "    res = graph.number_of_edges()\n",
    "    return res\n",
    "\n",
    "def degree(graph, mode='tot'):\n",
    "    if mode in 'tot': df = graph.degree()\n",
    "    elif mode in 'in': df = graph.in_degree()\n",
    "    elif mode in 'out': df = graph.out_degree()\n",
    "    \n",
    "    df = df.sort_values(by='vertex', ignore_index=True).compute()\n",
    "    return df\n",
    "\n",
    "def degree_distribution_wrapper(n, df) -> cudf.DataFrame:\n",
    "    \"\"\"\n",
    "    - df                cudf dataframe containing in/out/total degree per each node\n",
    "    - n                 number of vertices    \n",
    "    - mode              tot OR in OR out degree to specify nothing(??????????????)      \n",
    "    \"\"\"\n",
    "    degree_series = df['degree'].value_counts()\n",
    "    df_distribution = cudf.DataFrame({'degree': degree_series.index.to_cupy(),\n",
    "                                      'count': degree_series.to_cupy(), \n",
    "                                      'percentage': 0.0})\n",
    "    size = len(df_distribution)\n",
    "    compute_degree_distribution.forall(size)(n, df_distribution['count'],\n",
    "                                             df_distribution['percentage'])\n",
    "    df = dask_cudf.from_cudf(df_distribution, npartitions=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_bounds(x, y, bytess) -> int:\n",
    "    size = ((x * y * bytess) / 1e9)\n",
    "    if size > GPU_MEM_LIMIT:\n",
    "        x  = compute_bounds(int(x/2), y, bytess)\n",
    "    return x\n",
    "\n",
    "    \n",
    "def init_cc(n, batch_size, iteration, mod, N, nodes_cp=None, mode='local'):\n",
    "    \"\"\"\n",
    "    - n                 number of vertices of the graph\n",
    "    - batch_size        range of nodes examined each epoch\n",
    "    - iteration         current epoch\n",
    "    - mod               the margin of n / batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    if (batch_size * iteration) <= n:\n",
    "        start = 0 + (batch_size*(iteration - 1))\n",
    "        stop = start + batch_size\n",
    "        M = batch_size\n",
    "    else:\n",
    "        start = 0 + (batch_size*(iteration - 1))\n",
    "        stop = start + mod\n",
    "        M = mod\n",
    "    print(start, stop)\n",
    "    return start, stop, M\n",
    "        \n",
    "def avg_clustering_coefficient(n, src, dst, df_degree, N, nodes_cp=None, undirected=False) -> float:\n",
    "    local_ccs = cp.zeros((1,), dtype='float32')\n",
    "    M = compute_bounds(n, N, cp.dtype(cp.int32).itemsize)\n",
    "    epochs = ceil(n / M)\n",
    "    leftovers = n % M\n",
    "    \n",
    "    for i in range(1, epochs+1):  \n",
    "        start, stop, M = init_cc(n, M, i, leftovers, N)\n",
    "        nodes = cp.arange(start, stop, 1)\n",
    "        if nodes_cp is not None: nodes = nodes_cp[start : stop]\n",
    "        matrix = cp.empty((M, N), dtype='int32')\n",
    "        matrix.fill(-1)\n",
    "        edgespernode = cp.zeros(M, dtype='int32')\n",
    "        reciprocal = cp.zeros(M, dtype='int32')\n",
    "\n",
    "        threadsperblock = 1024\n",
    "        blockspergrid = (M + (threadsperblock -1)) // threadsperblock\n",
    "        threadsperblock_2D = (32, 32)\n",
    "        blockspergrid_x = (N + (threadsperblock_2D[1] - 1)) // threadsperblock_2D[1]\n",
    "        blockspergrid_y = (M + (threadsperblock_2D[0] - 1)) // threadsperblock_2D[0]\n",
    "        blockspergrid_2D = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "        adj_list[blockspergrid, threadsperblock](nodes, src, dst, undirected, matrix)\n",
    "        reciprocal_count[blockspergrid_2D, threadsperblock_2D](matrix, nodes, src, dst, M, N, reciprocal)\n",
    "        find_uv_edges[blockspergrid_2D, threadsperblock_2D](matrix, src, dst, M, N, undirected, edgespernode) \n",
    "        lcc[blockspergrid, threadsperblock](nodes, edgespernode, df_degree, reciprocal, undirected, local_ccs)\n",
    "        cuda.synchronize()\n",
    "\n",
    "\n",
    "    return local_ccs[0].get() / n\n",
    "\n",
    "def random_graph_generator(n, edges) -> cudf.DataFrame:\n",
    "    L = Graph(directed=True)\n",
    "    df = cudf.DataFrame({'src': None, 'dst': None})\n",
    "    p = edges / (n * (n - 1))\n",
    "    N = n\n",
    "    M = compute_bounds(n, N, cp.dtype(cp.int32).itemsize*4)\n",
    "    np_nodes = np.arange(0, n, 1, dtype='int32')\n",
    "    epochs = ceil(n / M)\n",
    "    leftovers = n % M\n",
    "    epoch = 1\n",
    "\n",
    "    while epoch <= epochs:\n",
    "        L.clear()\n",
    "        start, stop, M = init_cc(n, M, epoch, leftovers, N, mode='rndm')\n",
    "        matrix = cp.zeros((M, N), dtype='int32')\n",
    "        threadsperblock = 1024\n",
    "        blockspergrid = (matrix.shape[0] + (threadsperblock - 1)) // threadsperblock\n",
    "        rng_states = create_xoroshiro128p_states(threadsperblock * blockspergrid, seed=42)\n",
    "        gnp_erdos_renyi[blockspergrid, threadsperblock](p, rng_states, M, N, matrix)\n",
    "        a_matrix = np.empty((M,N), dtype='int32')\n",
    "        cp.asnumpy(matrix, stream=None, out=a_matrix)\n",
    "#        arrays.append(a_matrix)\n",
    "        L.from_numpy_array(a_matrix)\n",
    "        df_l = L.view_edge_list()\n",
    "        df_l.pop('weights')\n",
    "        size = len(df['src'])\n",
    "        align.forall(size)(df_l['src'], start)\n",
    "        df = cudf.concat([df, df_l], ignore_index=True)\n",
    "        del a_matrix\n",
    "        del matrix\n",
    "        epoch += 1\n",
    "    \n",
    "#    A = np.concatenate(arrays)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../graphs/ethereum/2020-01-01_2020-01-01/network.csv'\n",
    "ddf = load_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Graph(directed=True)\n",
    "G.from_dask_cudf_edgelist(ddf, source='src', destination='dst', edge_attr='wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_number = number_of_vertices(G)\n",
    "edges_number = number_of_edges(G)\n",
    "tot_degrees = degree(G, 'tot')\n",
    "in_degrees = degree(G, 'in')\n",
    "out_degrees = degree(G, 'out')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = degree_distribution_wrapper(vertex_number, tot_degrees)\n",
    "df_in = degree_distribution_wrapper(vertex_number, in_degrees)\n",
    "df_out = degree_distribution_wrapper(vertex_number, out_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = tot_degrees['degree'].max()\n",
    "src = ddf['src'].compute()\n",
    "dst = ddf['dst'].compute()\n",
    "#tot_deg = tot_degrees['degree'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_future = client.scatter([src, dst, tot_degrees['degree']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cc = client.submit(avg_clustering_coefficient, vertex_number, big_future[0],\n",
    "                       big_future[1], big_future[2], N, undirected=False)\n",
    "avg_cc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_components = dask_cugraph.weakly_connected_components(G)\n",
    "target_label = df_components['labels'].mode()[0].compute()\n",
    "target_label = target_label.iloc[0]\n",
    "df_nodes = df_components[df_components['labels'] == target_label].compute()\n",
    "ddf_mc = ddf.loc[ddf['src'].isin(df_nodes['vertex'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_mc = Graph(directed=True)\n",
    "G_mc.from_dask_cudf_edgelist(ddf_mc, source='src', destination='dst', edge_attr='wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_number_mc = number_of_vertices(G_mc)\n",
    "edges_number_mc = number_of_edges(G_mc)\n",
    "tot_degrees_mc = degree(G_mc, 'tot')\n",
    "in_degrees_mc = degree(G_mc, 'in')\n",
    "out_degrees_mc = degree(G_mc, 'out')\n",
    "vertices_mc = nodes(G_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_mc = degree_distribution_wrapper(vertex_number, tot_degrees)\n",
    "df_in_mc = degree_distribution_wrapper(vertex_number, in_degrees)\n",
    "df_out_mc = degree_distribution_wrapper(vertex_number, out_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = tot_degrees_mc['degree'].max()\n",
    "src_mc = ddf_mc['src'].compute()\n",
    "dst_mc = ddf_mc['dst'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_future = client.scatter([src_mc, dst_mc, tot_degrees_mc['degree']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cc_mc = client.submit(avg_clustering_coefficient, vertex_number_mc, big_future[0],\n",
    "                       big_future[1], big_future[2], N, nodes_cp=vertices_mc, undirected=False)\n",
    "avg_cc_mc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_rnd = client.submit(random_graph_generator, vertex_number, edges_number)\n",
    "edges_rnd.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DiLeNa_rapidsai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "205f03a9084886247c431e04be0474db8fe3c88af0920dc2b52a09012fb59654"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
